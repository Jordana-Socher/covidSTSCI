test = na.omit(test)
testing = test$gdp_per_capita
# How do these regressors predict how corrupt a country is? How does this compare to model excluding
# covid numbers etc. Do we need some model selection technique? Grid search?
#lda = lda(gdp_per_capita ~ total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda = lda(gdp_per_capita ~  total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda_pred = predict(lda, test)
#error = mean(lda_pred$class != testing)
#error
#kNN
train2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[training, ]
test2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[-training, ]
class = transpose(as.data.frame(subset(train, select = c(gdp_per_capita))))
accum = c()
for (numC in c(1, 2, 3, 5, 10, 20)){
knn_pred = knn(train2, test2, class, k = numC)
error = mean(knn_pred != testing)
accum = append(accum, error)
print(error)
}
plot(accum)
View(train2)
View(test2)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData[is.na(masterData)] = 0
training =sample(1:nrow(masterData),nrow(masterData)/2, replace = FALSE)
train = masterData[training,]
test = masterData[-training,]
testing = test$gdp_per_capita
# How do these regressors predict how corrupt a country is? How does this compare to model excluding
# covid numbers etc. Do we need some model selection technique? Grid search?
#lda = lda(gdp_per_capita ~ total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda = lda(gdp_per_capita ~  total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda_pred = predict(lda, test)
#error = mean(lda_pred$class != testing)
#error
#kNN
train2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[training, ]
test2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[-training, ]
class = transpose(as.data.frame(subset(train2, select = c(gdp_per_capita))))
accum = c()
for (numC in c(1, 2, 3, 5, 10, 20)){
knn_pred = knn(train2, test2, class, k = numC)
error = mean(knn_pred != testing)
accum = append(accum, error)
print(error)
}
plot(accum)
rm(list = ls())
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData[is.na(masterData)] = 0
training =sample(1:nrow(masterData),nrow(masterData)/2, replace = FALSE)
train = masterData[training,]
test = masterData[-training,]
testing = test$gdp_per_capita
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData[is.na(masterData)] = 0
training =sample(1:nrow(masterData),nrow(masterData)/2, replace = FALSE)
train = masterData[training,]
test = masterData[-training,]
testing = test$gdp_per_capita
train2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[training, ]
test2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[-training, ]
class = transpose(as.data.frame(subset(train2, select = c(gdp_per_capita))))
class = transpose(as.data.frame(subset(train2, select = c(gdp_per_capita))))
class = transpose(as.data.frame(subset(train2, select = c(gdp_per_capita))))
View(train2)
View(train)
class = transpose(as.data.frame(subset(train, select = c(gdp_per_capita))))
accum = c()
for (numC in c(1, 2, 3, 5, 10, 20)){
knn_pred = knn(train2, test2, class, k = numC)
error = mean(knn_pred != testing)
accum = append(accum, error)
print(error)
}
plot(accum)
View(masterData)
View(test2)
masterData[is.na(masterData)] = 0
View(masterData)
masterData = masterData[is.na(masterData)] = 0
rm(list = ls())
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData = masterData[is.na(masterData)] = 0
myDataframe[is.na(myDataframe)] = 0
training =sample(1:nrow(masterData),nrow(masterData)/2, replace = FALSE)
train = masterData[training,]
test = masterData[-training,]
testing = test$gdp_per_capita
# How do these regressors predict how corrupt a country is? How does this compare to model excluding
# covid numbers etc. Do we need some model selection technique? Grid search?
#lda = lda(gdp_per_capita ~ total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda = lda(gdp_per_capita ~  total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda_pred = predict(lda, test)
#error = mean(lda_pred$class != testing)
#error
#kNN
train2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[training, ]
test2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[-training, ]
class = transpose(as.data.frame(subset(train, select = c(gdp_per_capita))))
training =sample(1:nrow(masterData),nrow(masterData)/2, replace = FALSE)
train = masterData[training,]
test = masterData[-training,]
testing = test$gdp_per_capita
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
attach(masterData)
View(masterData)
View(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData[is.na(masterData)] = 0
View(masterData)
training =sample(1:nrow(masterData),nrow(masterData)/2, replace = FALSE)
train = masterData[training,]
test = masterData[-training,]
testing = test$gdp_per_capita
View(test)
View(train)
View(masterData)
rm(list = ls())
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData[is.na(masterData)] = 0
training =sample(1:nrow(masterData),nrow(masterData)/2, replace = FALSE)
train = masterData[training,]
test = masterData[-training,]
testing = test$gdp_per_capita
testing
training
train
test
testing = test$gdp_per_capita
testing
train2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[training, ]
View(train)
View(train2)
train2[is.na(train2)] = 0
masterData
test2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[-training, ]
test2[is.na(test2)] = 0
class = transpose(as.data.frame(subset(train, select = c(gdp_per_capita))))
accum = c()
for (numC in c(1, 2, 3, 5, 10, 20)){
knn_pred = knn(train2, test2, class, k = numC)
error = mean(knn_pred != testing)
accum = append(accum, error)
print(error)
}
plot(accum)
rm(list = ls())
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData[is.na(masterData)] = 0
med = median(gdp_per_capita)
gdp50 <- ifelse(gdp_per_capita > med, yes = 1, no = 0)
training =sample(1:nrow(masterData),nrow(masterData)/2, replace = FALSE)
train = masterData[training,]
test = masterData[-training,]
testing = test$gdp50
# How do these regressors predict how corrupt a country is? How does this compare to model excluding
# covid numbers etc. Do we need some model selection technique? Grid search?
#lda = lda(gdp_per_capita ~ total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda = lda(gdp_per_capita ~  total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda_pred = predict(lda, test)
#error = mean(lda_pred$class != testing)
#error
#kNN
train2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[training, ]
train2[is.na(train2)] = 0
test2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[-training, ]
test2[is.na(test2)] = 0
class = transpose(as.data.frame(subset(train, select = c(gdp50))))
accum = c()
for (numC in c(1, 2, 3, 5, 10, 20)){
knn_pred = knn(train2, test2, class, k = numC)
error = mean(knn_pred != testing)
accum = append(accum, error)
print(error)
}
plot(accum)
rm(list = ls())
source("dataBuild.R")
load("covidCorruption.RData")
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData[is.na(masterData)] = 0
med = median(gdp_per_capita)
gdp50 <- ifelse(gdp_per_capita > med, yes = 1, no = 0)
training =sample(1:nrow(masterData),nrow(masterData)/2, replace = FALSE)
train = masterData[training,]
test = masterData[-training,]
testing = test$gdp50
train2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[training, ]
train2[is.na(train2)] = 0
test2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[-training, ]
test2[is.na(test2)] = 0
class = transpose(as.data.frame(subset(train, select = c(gdp50))))
accum = c()
for (numC in c(1, 2, 3, 5, 10, 20)){
knn_pred = knn(train2, test2, class, k = numC)
error = mean(knn_pred != testing)
accum = append(accum, error)
print(error)
}
med
med = median(gdp_per_capita)
med
med = median(masterData$gdp_per_capita)
med
rm(list = ls())
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData[is.na(masterData)] = 0
med = median(masterData$gdp_per_capita)
gdp50 <- ifelse(gdp_per_capita > med, yes = 1, no = 0)
training =sample(1:nrow(masterData),nrow(masterData)/2, replace = FALSE)
train = masterData[training,]
test = masterData[-training,]
testing = test$gdp50
# How do these regressors predict how corrupt a country is? How does this compare to model excluding
# covid numbers etc. Do we need some model selection technique? Grid search?
#lda = lda(gdp_per_capita ~ total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda = lda(gdp_per_capita ~  total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda_pred = predict(lda, test)
#error = mean(lda_pred$class != testing)
#error
#kNN
train2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[training, ]
train2[is.na(train2)] = 0
test2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[-training, ]
test2[is.na(test2)] = 0
class = transpose(as.data.frame(subset(train, select = c(gdp50))))
accum = c()
for (numC in c(1, 2, 3, 5, 10, 20)){
knn_pred = knn(train2, test2, class, k = numC)
error = mean(knn_pred != testing)
accum = append(accum, error)
print(error)
}
plot(accum)
accum = c()
for (numC in c(1, 2, 3, 5, 10, 20)){
knn_pred = knn(train2, test2, class, k = numC)
error = mean(knn_pred != testing)
accum = append(accum, error)
print(error)
}
train2
test2
clas
clas
class
rm(list = ls())
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData[is.na(masterData)] = 0
med = median(masterData$gdp_per_capita)
medGDP <- ifelse(gdp_per_capita > med, yes = 1, no = 0)
training =sample(1:nrow(masterData),nrow(masterData)/2, replace = FALSE)
train = masterData[training,]
test = masterData[-training,]
testing = test$medGDP
# How do these regressors predict how corrupt a country is? How does this compare to model excluding
# covid numbers etc. Do we need some model selection technique? Grid search?
#lda = lda(gdp_per_capita ~ total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda = lda(gdp_per_capita ~  total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda_pred = predict(lda, test)
#error = mean(lda_pred$class != testing)
#error
#kNN
train2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[training, ]
train2[is.na(train2)] = 0
test2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[-training, ]
test2[is.na(test2)] = 0
class = transpose(as.data.frame(subset(train, select = c(medGDP))))
accum = c()
for (numC in c(1, 2, 3, 5, 10, 20)){
knn_pred = knn(train2, test2, class, k = numC)
error = mean(knn_pred != testing)
accum = append(accum, error)
print(error)
}
plot(accum)
accum = c()
for (numC in c(1, 2, 3, 5, 10, 20)){
knn_pred = knn(train2, test2, class, k = numC)
error = mean(knn_pred != testing)
accum = append(accum, error)
print(error)
}
class = transpose(as.data.frame(subset(train, select = c(medGDP))))
medGDP
medGDP <- ifelse(gdp_per_capita >= med, yes = 1, no = 0)
medGDP
View(masterData)
masterData$medGDP = medGDP
View(masterData)
<<<<<<< HEAD
ggplot(data = world) +
geom_sf()
library("ggplot2")
theme_set(theme_bw())
library("sf")
"ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata")
install.packages(c("cowplot", "googleway", "ggplot2", "ggrepel",
"ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata"))
install.packages(c("cowplot", "googleway", "ggplot2", "ggrepel", "ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata"))
install.packages(c("cowplot", "googleway", "ggplot2", "ggrepel", "ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata"))
install.packages(c("cowplot", "googleway", "ggplot2", "ggrepel", "ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata"))
library("ggplot2")
theme_set(theme_bw())
library("sf")
ggplot(data = world) +
geom_sf()
library("ggplot2")
library("rnaturalearth")
library("rnaturalearthdata")
world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)
world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)
world <- ne_countries(scale = "medium", returnclass = "sf")
install.packages(c("cowplot", "googleway", "ggplot2", "ggrepel",
"ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata"))
install.packages(c("cowplot", "googleway", "ggplot2", "ggrepel", "ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata"))
library("ggplot2")
library("ggplot2")
#install.packages(c("cowplot", "googleway", "ggplot2", "ggrepel",
#"ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata"))
library("ggplot2")
theme_set(theme_bw())
library("sf")
library("rnaturalearth")
library("rnaturalearthdata")
world <- ne_countries(scale = "medium", returnclass = "sf")
install.packages(c("cowplot","googleway", "ggplot2", "ggrepel",
"ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata",
"rgeos"))
install.packages(c("cowplot", "googleway", "ggplot2", "ggrepel", "ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata", "rgeos"))
#install.packages(c("cowplot","googleway", "ggplot2", "ggrepel",
#                   "ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata",
#                   "rgeos"))
library("ggplot2")
theme_set(theme_bw())
library("sf")
library("rnaturalearth")
library("rnaturalearthdata")
library(rgeos)
world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)
ggplot(data = world) +
geom_sf()
ggplot(data = world) +
geom_sf() +
xlab("Longitude") + ylab("Latitude") +
ggtitle("World map", subtitle = paste0("(", length(unique(world$NAME)), " countries)"))
View(world)
ggplot(data = world) +
geom_sf() +
xlab("Longitude") + ylab("Latitude") +
ggtitle("World map", subtitle = paste0("(", length(unique(world$name_long)), " countries)"))
ggplot(data = world) +
geom_sf(aes(fill = pop_est)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
View(world)
View(masterData)
load("covidCorruption.RData")
x<-load("covidCorruption.RData")
load("covidCorruption.RData")
# Summary plots below are not too substantive. Goal is to visualize the new data
# and evidence our prediction argument. Note, our project pays no attention to a
# time series, where we have isolated the data from the last day in the dataset.
# What might be worthwhile, is including (down the road) line graphs connecting
# three points, for a handful of countries, over time. For example, Mar1, June1, Oct19.
covid<-load("COVID.xlsx")
install("readxl")
install.packages("readxl")
#install.packages("readxl")
library("readxl")
covid<-read_excel("COVID.xlsx")
View(covid)
y<-covid%>%group_by(location)%>%summarise(max(total_cases/population))
library(dplyr)
y<-covid%>%group_by(location)%>%summarise(max(total_cases/population))
View(y)
View(masterData)
y<-covid%>%group_by(location)%>%summarise(max(total_cases/population))%>% drop_na()
y<- DropNA(y, Var = "max(total_cases/population)")
y<-covid%>%group_by(location)%>%summarise(max(total_cases/population))%>% drop_na()
y<- DropNA(y, Var = "max(total_cases/population)")
y<- DropNA(y)
library(tidyr)
y<-covid%>%group_by(location)%>%summarise(max(total_cases/population))%>% drop_na()
View(y)
covid$caseRatePer100k = covid$total_cases/(covid$population/100000)
y<-covid%>%group_by(location)%>%summarise(max(caseRatePer100k))
View(y)
covid<-covid.drop_na()
covid<-drop_na(covid)
y<-covid%>%group_by(location)%>%summarise(max(caseRatePer100k))
View(y)
covid<-read_excel("COVID.xlsx")
View(covid)
covid<-drop_na(covid$total_cases)
covid%>%drop_na(total_cases, population)
covid<-covid%>%drop_na(total_cases, population)
View(covid)
covid$caseRatePer100k = covid$total_cases/(covid$population/100000)
y<-covid%>%group_by(location)%>%summarise(max(caseRatePer100k))
View(y)
ggplot(data = covid) +
geom_sf(aes(fill = max(caseRatePer100k))) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
world1 <- covid(scale = "medium", returnclass = "sf")
class(world1)
world_1=merge(world, covid, by.x="name", by.y="location")
class(world1)
world_1=merge(world, covid, by.x="name", by.y="location")
class(world_1)
View(world_1)
View(world_1)
world_1=merge(world, y, by.x="name", by.y="location")
class(world_1)
View(world_1)
ggplot(data = world_1) +
geom_sf(aes(fill = max(caseRatePer100k))) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
ggplot(data = world_1) +
geom_sf(aes(fill = "max(caseRatePer100k)")) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
world_1%>%rename(max(caseRatePer100k)=max_case_rate)
names(world_1)[names(world_1) == "max(caseRatePer100k)"] <- "max_case_rate"
View(world_1)
ggplot(data = world_1) +
geom_sf(aes(fill = max_case_rate)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
z<-covid%>%group_by(location)%>%summarise(gdp_per_capita)
View(z)
z<-covid%>%group_by(location)%>%summarise(max(gdp_per_capita))
View(z)
covid<-covid%>%drop_na(total_cases, population, gdp_per_capita)
z<-covid%>%group_by(location)%>%summarise(max(gdp_per_capita))
covid<-covid%>%drop_na(total_cases, population, gdp_per_capita)
covid$caseRatePer100k = covid$total_cases/(covid$population/100000)
y<-covid%>%group_by(location)%>%summarise(max(caseRatePer100k))
z<-covid%>%group_by(location)%>%summarise(max(gdp_per_capita))
View(z)
world_2=merge(world, y, by.x="name", by.y="location")
names(world_1)[names(world_1) == "max(gdp_per_capita)"] <- "gdp"
ggplot(data = world_2) +
geom_sf(aes(fill = gdp)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
world_2=merge(world, y, by.x="name", by.y="location")
names(world_1)[names(world_1) == "max(gdp_per_capita)"] <- "gdp"
z<-covid%>%group_by(location)%>%summarise(max(gdp_per_capita))
world_2=merge(world, z, by.x="name", by.y="location")
names(world_1)[names(world_1) == "max(gdp_per_capita)"] <- "gdp"
ggplot(data = world_2) +
geom_sf(aes(fill = gdp)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
source("dataBuild.R")
load("covidCorruption.RData")
#install.packages("readxl")
library("readxl")
covid<-read_excel("COVID.xlsx")
library(dplyr)
library(tidyr)
covid<-covid%>%drop_na(total_cases, population, gdp_per_capita)
covid$caseRatePer100k = covid$total_cases/(covid$population/100000)
y<-covid%>%group_by(location)%>%summarise(max(caseRatePer100k))
z<-covid%>%group_by(location)%>%summarise(max(gdp_per_capita))
#install.packages(c("cowplot","googleway", "ggplot2", "ggrepel",
#                   "ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata",
#                   "rgeos"))
library("ggplot2")
theme_set(theme_bw())
library("sf")
library("rnaturalearth")
library("rnaturalearthdata")
library(rgeos)
world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)
world_1=merge(world, y, by.x="name", by.y="location")
names(world_1)[names(world_1) == "max(caseRatePer100k)"] <- "max_case_rate"
world_2=merge(world, z, by.x="name", by.y="location")
names(world_1)[names(world_1) == "max(gdp_per_capita)"] <- "gdp"
ggplot(data = world_2) +
geom_sf(aes(fill = gdp)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
View(z)
names(world_2)[names(world_1) == "max(gdp_per_capita)"] <- "gdp"
ggplot(data = world_2) +
geom_sf(aes(fill = gdp)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
source("dataBuild.R")
load("covidCorruption.RData")
library("readxl")
covid<-read_excel("COVID.xlsx")
library(dplyr)
library(tidyr)
covid<-covid%>%drop_na(total_cases, population, gdp_per_capita)
covid$caseRatePer100k = covid$total_cases/(covid$population/100000)
y<-covid%>%group_by(location)%>%summarise(max(caseRatePer100k))
z<-covid%>%group_by(location)%>%summarise(max(gdp_per_capita))
#install.packages(c("cowplot","googleway", "ggplot2", "ggrepel",
#                   "ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata",
#                   "rgeos"))
library("ggplot2")
theme_set(theme_bw())
library("sf")
library("rnaturalearth")
library("rnaturalearthdata")
library(rgeos)
world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)
world_1=merge(world, y, by.x="name", by.y="location")
names(world_1)[names(world_1) == "max(caseRatePer100k)"] <- "max_case_rate"
world_2=merge(world, z, by.x="name", by.y="location")
names(world_2)[names(world_2) == "max(gdp_per_capita)"] <- "gdp"
ggplot(data = world_2) +
geom_sf(aes(fill = gdp)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
View(masterData)
world_2=merge(world, masterData, by.x="name", by.y="location")
ggplot(data = world_2) +
geom_sf(aes(fill = gdp_per_capita)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
View(masterData)
ggplot(data = world_2) +
geom_sf(aes(fill = corruption_rank)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
ggplot(data = world_2) +
geom_sf(aes(fill = corruptionRank)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
View(world_2)
typeof(world_2$corruptionRank)
typeof(world_2$gdp_per_capita)
world_2$gdp_per_capita=as.double(world_2$gdp_per_capita)
ggplot(data = world_2) +
geom_sf(aes(fill = corruptionRank)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
typeof(world_2$gdp_per_capita)
typeof(world_2$gdp_per_capita)
world_2$corruptionRank=as.double(world_2$corruptionRank)
View(world_2)
ggplot(data = world_2) +
geom_sf(aes(fill = corruptionRank)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
source("dataBuild.R")
load("covidCorruption.RData")
library("readxl")
library(dplyr)
library(tidyr)
library("ggplot2")
theme_set(theme_bw())
library("sf")
library("rnaturalearth")
library("rnaturalearthdata")
library(rgeos)
#bringing in covid data alone to get the specific max case rate per country
covid<-read_excel("COVID.xlsx")
plot1 = ggplot(data =masterData, aes(x = caseRatePer100k, y = deathRatePer100k)) + geom_text(aes(label = location), size = 2) + geom_smooth(method = "lm")
plot2 = ggplot(data =masterData, aes(x = corruptionRank, y = deathRatePer100k)) + geom_text(aes(label = location), size = 2) + geom_smooth(method = "lm")
plot3 = ggplot(data =masterData, aes(x = govRank, y = deathRatePer100k)) + geom_text(aes(label = location), size = 2) + geom_smooth(method = "lm")
plot4 = ggplot(data =masterData, aes(x = stabilityRank, y = deathRatePer100k)) + geom_text(aes(label = location), size = 2) + geom_smooth(method = "lm")
plot5 = ggplot(data =masterData, aes(x = gdp_per_capita, y = deathRatePer100k)) + geom_text(aes(label = location), size = 2) + geom_smooth(method = "lm")
plot6 = ggplot(data =masterData, aes(x = gdp_per_capita, y = corruptionRank)) + geom_text(aes(label = location), size = 2) + geom_smooth(method = "lm")
plot7 = ggplot(data =masterData, aes(x = gdp_per_capita, y = corruptionRank)) + geom_text(aes(label = location), size = 2) + geom_smooth(method = "lm")
plot1
plot2
plot3
plot4
plot6
plot7
covid<-covid%>%drop_na(total_cases, population, gdp_per_capita)
covid$caseRatePer100k = covid$total_cases/(covid$population/100000)
covid_max_rate_df<-covid%>%group_by(location)%>%summarise(max(caseRatePer100k))
#using ne_countries to get map of countries
world <- ne_countries(scale = "medium", returnclass = "sf")
world_1=merge(world, covid_max_rate_df, by.x="name", by.y="location")
names(world_1)[names(world_1) == "max(caseRatePer100k)"] <- "max_case_rate"
world_2=merge(world, masterData, by.x="name", by.y="location")
world_2$corruptionRank=as.double(world_2$corruptionRank)
ggplot(data = world_1) +
geom_sf(aes(fill = max_case_rate)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
ggplot(data = world_2) +
geom_sf(aes(fill = gdp_per_capita)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
ggplot(data = world_2) +
geom_sf(aes(fill = corruptionRank)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
source("dataBuild.R")
load("covidCorruption.RData")
library("readxl")
library(dplyr)
library(tidyr)
library("ggplot2")
theme_set(theme_bw())
library("sf")
library("rnaturalearth")
library("rnaturalearthdata")
library(rgeos)
#bringing in covid data alone to get the specific max case rate per country
covid<-read_excel("COVID.xlsx")
covid<-covid%>%drop_na(total_cases, population, gdp_per_capita)
covid$caseRatePer100k = covid$total_cases/(covid$population/100000)
covid_max_rate_df<-covid%>%group_by(location)%>%summarise(max(caseRatePer100k))
#using ne_countries to get map of countries
world <- ne_countries(scale = "medium", returnclass = "sf")
#merging world df with covid_max_rate_df to plot and renaming column
world_1=merge(world, covid_max_rate_df, by.x="name", by.y="location")
names(world_1)[names(world_1) == "max(caseRatePer100k)"] <- "max_case_rate"
#merging world with masterData df to plot corruption and gdp
world_2=merge(world, masterData, by.x="name", by.y="location")
world_2$corruptionRank=as.double(world_2$corruptionRank)
#world plot of max case rate per country
ggplot(data = world_1) +
geom_sf(aes(fill = max_case_rate)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
ggplot(data = world_2) +
geom_sf(aes(fill = gdp_per_capita)) +
scale_fill_viridis_c(option = "plasma", trans = "sqrt")
=======
rm(list = ls())
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
masterData = masterData[order(masterData$gdp_per_capita),]
masterData[is.na(masterData)] = 0
med = median(masterData$gdp_per_capita)
medGDP <- ifelse(gdp_per_capita >= med, yes = 1, no = 0)
masterData$medGDP = medGDP
View(masterData)
medGDP <- ifelse(gdp_per_capita >= med, yes = 1, no = 0)
medGDP <- ifelse(masterData$gdp_per_capita >= med, yes = 1, no = 0)
medGDP
rm(list = ls())
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData[is.na(masterData)] = 0
med = median(masterData$gdp_per_capita)
medGDP <- ifelse(masterData$gdp_per_capita >= med, yes = 1, no = 0)
masterData$medGDP = medGDP
training =sample(1:nrow(masterData),nrow(masterData)/2, replace = FALSE)
train = masterData[training,]
test = masterData[-training,]
testing = test$medGDP
# How do these regressors predict how corrupt a country is? How does this compare to model excluding
# covid numbers etc. Do we need some model selection technique? Grid search?
#lda = lda(gdp_per_capita ~ total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda = lda(gdp_per_capita ~  total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda_pred = predict(lda, test)
#error = mean(lda_pred$class != testing)
#error
#kNN
train2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[training, ]
train2[is.na(train2)] = 0
test2 = cbind(total_cases, total_deaths, population, stringency_index, human_development_index)[-training, ]
test2[is.na(test2)] = 0
class = transpose(as.data.frame(subset(train, select = c(medGDP))))
accum = c()
for (numC in c(1, 2, 3, 5, 10, 20)){
knn_pred = knn(train2, test2, class, k = numC)
error = mean(knn_pred != testing)
accum = append(accum, error)
print(error)
}
plot(accum)
rm(list = ls())
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData[is.na(masterData)] = 0
med = median(masterData$gdp_per_capita)
medGDP <- ifelse(masterData$gdp_per_capita >= med, yes = 1, no = 0)
masterData$medGDP = medGDP
training =sample(1:nrow(masterData),nrow(masterData)/2, replace = FALSE)
train = masterData[training,]
test = masterData[-training,]
testing = test$medGDP
# How do these regressors predict how corrupt a country is? How does this compare to model excluding
# covid numbers etc. Do we need some model selection technique? Grid search?
#lda = lda(gdp_per_capita ~ total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda = lda(gdp_per_capita ~  total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda_pred = predict(lda, test)
#error = mean(lda_pred$class != testing)
#error
#kNN
train2 = cbind(population, stringency_index, human_development_index)[training, ]
train2[is.na(train2)] = 0
test2 = cbind(population, stringency_index, human_development_index)[-training, ]
test2[is.na(test2)] = 0
class = transpose(as.data.frame(subset(train, select = c(medGDP))))
accum = c()
for (numC in c(1, 2, 3, 5, 10, 20)){
knn_pred = knn(train2, test2, class, k = numC)
error = mean(knn_pred != testing)
accum = append(accum, error)
print(error)
}
plot(accum)
medGDP
View(masterData)
rm(list = ls())
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData = na.omit(masterData)
med = median(masterData$gdp_per_capita)
medGDP <- ifelse(masterData$gdp_per_capita >= med, yes = 1, no = 0)
masterData$medGDP = medGDP
training =sample(1:nrow(masterData),nrow(masterData)/2, replace = FALSE)
train = masterData[training,]
test = masterData[-training,]
testing = test$medGDP
# How do these regressors predict how corrupt a country is? How does this compare to model excluding
# covid numbers etc. Do we need some model selection technique? Grid search?
#lda = lda(gdp_per_capita ~ total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda = lda(gdp_per_capita ~  total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda_pred = predict(lda, test)
#error = mean(lda_pred$class != testing)
#error
#kNN
train2 = cbind(population, stringency_index, human_development_index)[training, ]
train2[is.na(train2)] = 0
test2 = cbind(population, stringency_index, human_development_index)[-training, ]
test2[is.na(test2)] = 0
class = transpose(as.data.frame(subset(train, select = c(medGDP))))
accum = c()
for (numC in c(1, 2, 3, 5, 10, 20)){
knn_pred = knn(train2, test2, class, k = numC)
error = mean(knn_pred != testing)
accum = append(accum, error)
print(error)
}
plot(accum)
rm(list = ls())
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData = na.omit(masterData)
View(masterData)
rm(list = ls())
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData = na.omit(masterData$gdp_per_capita)
masterData
masterData = na.omit(masterDat)
masterData = na.omit(masterData)
rm(list = ls())
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData = na.omit(masterData)
View(masterData)
rm(list = ls())
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData =  DropNA(masterData, Var = c("gdp_per_capita"))
masterData =  drop_na(masterData, Var = c("gdp_per_capita"))
masterData =  drop_na(gdp_per_capita)
masterData =  drop_na(c("gdp_per_capita"))
View(masterData)
rm(list = ls())
source("dataBuild.R")
load("covidCorruption.RData")
# Normalize data and split into training test
attach(masterData)
masterData = masterData[order(masterData$gdp_per_capita),]
masterData =  drop_na(c("gdp_per_capita"))
med = median(masterData$gdp_per_capita)
medGDP <- ifelse(masterData$gdp_per_capita >= med, yes = 1, no = 0)
masterData$medGDP = medGDP
training =sample(1:nrow(masterData),nrow(masterData)/2, replace = FALSE)
train = masterData[training,]
test = masterData[-training,]
testing = test$medGDP
# How do these regressors predict how corrupt a country is? How does this compare to model excluding
# covid numbers etc. Do we need some model selection technique? Grid search?
#lda = lda(gdp_per_capita ~ total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda = lda(gdp_per_capita ~  total_cases + total_deaths + population + stringency_index + human_development_index, data=masterData, subset = training)
#lda_pred = predict(lda, test)
#error = mean(lda_pred$class != testing)
#error
#kNN
train2 = cbind(population, stringency_index, human_development_index)[training, ]
train2[is.na(train2)] = 0
test2 = cbind(population, stringency_index, human_development_index)[-training, ]
test2[is.na(test2)] = 0
class = transpose(as.data.frame(subset(train, select = c(medGDP))))
accum = c()
for (numC in c(1, 2, 3, 5, 10, 20)){
knn_pred = knn(train2, test2, class, k = numC)
error = mean(knn_pred != testing)
accum = append(accum, error)
print(error)
}
plot(accum)
>>>>>>> 8204fd4bc4a14a5366ed94fbeb5d467c0955a4b2
